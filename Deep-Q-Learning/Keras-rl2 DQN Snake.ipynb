{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30d6aeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image  # To transform the image in the Processor\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "# Convolutional Backbone Network\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Convolution2D, Permute\n",
    "\n",
    "# Keras-RL\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.core import Processor\n",
    "from rl.callbacks import FileLogger, ModelIntervalCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfb7b904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.9.16)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"snake:yeks_snake-v0\")\n",
    "nb_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "495761aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef0e07b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19b442ea310>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "env.reset()\n",
    "env.render('human')\n",
    "action = env.action_space.sample()\n",
    "img,reward,done,info = env.step(action)\n",
    "plt.figure()\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ce1f486",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (84, 84)\n",
    "WINDOW_LENGTH = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0de160b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProcessor(Processor):\n",
    "    def process_observation(self, observation):\n",
    "        # First convert the numpy array to a PIL Image\n",
    "        img = Image.fromarray(observation)\n",
    "        # Then resize the image\n",
    "        img = img.resize(IMG_SHAPE)\n",
    "        # And convert it to grayscale  (The L stands for luminance)\n",
    "        img = img.convert(\"L\")\n",
    "        # Convert the image back to a numpy array and finally return the image\n",
    "        img = np.array(img)\n",
    "        return img.astype('uint8')  # saves storage in experience memory\n",
    "    \n",
    "    def process_state_batch(self, batch):\n",
    "\n",
    "        # We divide the observations by 255 to compress it into the intervall [0, 1].\n",
    "        # This supports the training of the network\n",
    "        # We perform this operation here to save memory.\n",
    "        processed_batch = batch.astype('float32') / 255.\n",
    "        return processed_batch\n",
    "\n",
    "    def process_reward(self, reward):\n",
    "        return np.clip(reward, -1., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea995218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 84, 84)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = (WINDOW_LENGTH, IMG_SHAPE[0], IMG_SHAPE[1])\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "013bc283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " permute (Permute)           (None, 84, 84, 4)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 20, 20, 32)        8224      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 20, 20, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 9, 9, 64)          32832     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 9, 9, 64)          0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1606144   \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 2052      \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,686,180\n",
      "Trainable params: 1,686,180\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Permute((2, 3, 1), input_shape=input_shape))\n",
    "\n",
    "model.add(Convolution2D(32, (8, 8), strides=(4, 4),kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, (4, 4), strides=(2, 2), kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, (3, 3), strides=(1, 1), kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_actions))\n",
    "model.add(Activation('linear'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1672009",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = SequentialMemory(limit=1000000, window_length=WINDOW_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "600bd826",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ImageProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92e02ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=1., value_min=.1, value_test=.05,\n",
    "                              nb_steps=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f496ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn = DQNAgent(model=model, nb_actions=nb_actions, policy=policy, memory=memory,\n",
    "               processor=processor, nb_steps_warmup=50000, gamma=.99, target_model_update=10000,\n",
    "              train_interval=4, delta_clip=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b273e1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\gym\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "dqn.compile(tf.keras.optimizers.Adam(learning_rate=.00025), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b381b017",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_filename = 'test_dqn_snake_weights.h5f'\n",
    "checkpoint_weights_filename = 'test_dqn_' + \"snake\" + '_weights_{step}.h5f'\n",
    "checkpoint_callback = ModelIntervalCheckpoint(checkpoint_weights_filename, interval=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee92c597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 1500000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      "    16/100000 [..............................] - ETA: 11:47 - reward: -0.3125    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\gym\\lib\\site-packages\\keras\\engine\\training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50004/100000 [==============>...............] - ETA: 6:07 - reward: -0.2476"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Adam' object has no attribute 'get_updates'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdqn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnb_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1500000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# After training is done, we save the final weights one more time.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m dqn\u001b[38;5;241m.\u001b[39msave_weights(weights_filename, overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gym\\lib\\site-packages\\rl\\core.py:215\u001b[0m, in \u001b[0;36mAgent.fit\u001b[1;34m(self, env, nb_steps, action_repetition, callbacks, verbose, visualize, nb_max_start_steps, start_step_policy, log_interval, nb_max_episode_steps)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;66;03m# We are in a terminal state but the agent hasn't yet seen it. We therefore\u001b[39;00m\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;66;03m# perform one more forward-backward call and simply ignore the action before\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;66;03m# resetting the environment. We need to pass in `terminal=False` here since\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m# the *next* state, that is the state of the newly reset environment, is\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# always non-terminal by convention.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(observation)\n\u001b[1;32m--> 215\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mterminal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# This episode is finished, report and reset.\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     episode_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepisode_reward\u001b[39m\u001b[38;5;124m'\u001b[39m: episode_reward,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnb_episode_steps\u001b[39m\u001b[38;5;124m'\u001b[39m: episode_step,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnb_steps\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep,\n\u001b[0;32m    222\u001b[0m     }\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gym\\lib\\site-packages\\rl\\agents\\dqn.py:321\u001b[0m, in \u001b[0;36mDQNAgent.backward\u001b[1;34m(self, reward, terminal)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;66;03m# Finally, perform a single update on the entire batch. We use a dummy target since\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# the actual loss is computed in a Lambda layer that needs more complex input. However,\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;66;03m# it is still useful to know the actual target to compute metrics properly.\u001b[39;00m\n\u001b[0;32m    320\u001b[0m ins \u001b[38;5;241m=\u001b[39m [state0_batch] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39minput) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlist\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m state0_batch\n\u001b[1;32m--> 321\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mins\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mdummy_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m metrics \u001b[38;5;241m=\u001b[39m [metric \u001b[38;5;28;01mfor\u001b[39;00m idx, metric \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(metrics) \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)]  \u001b[38;5;66;03m# throw away individual losses\u001b[39;00m\n\u001b[0;32m    323\u001b[0m metrics \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mmetrics\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gym\\lib\\site-packages\\keras\\engine\\training_v1.py:1178\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1175\u001b[0m         ins \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mTrue\u001b[39;00m]  \u001b[38;5;66;03m# Add learning phase value.\u001b[39;00m\n\u001b[0;32m   1177\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_sample_weight_modes(sample_weights\u001b[38;5;241m=\u001b[39msample_weights)\n\u001b[1;32m-> 1178\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_train_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1179\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(ins)\n\u001b[0;32m   1181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reset_metrics:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\gym\\lib\\site-packages\\keras\\engine\\training_v1.py:2282\u001b[0m, in \u001b[0;36mModel._make_train_function\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2279\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mget_graph()\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[0;32m   2280\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   2281\u001b[0m         \u001b[38;5;66;03m# Training updates\u001b[39;00m\n\u001b[1;32m-> 2282\u001b[0m         updates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_updates\u001b[49m(\n\u001b[0;32m   2283\u001b[0m             params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collected_trainable_weights,\n\u001b[0;32m   2284\u001b[0m             loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_loss,\n\u001b[0;32m   2285\u001b[0m         )\n\u001b[0;32m   2286\u001b[0m         \u001b[38;5;66;03m# Unconditional updates\u001b[39;00m\n\u001b[0;32m   2287\u001b[0m         updates \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_updates_for(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Adam' object has no attribute 'get_updates'"
     ]
    }
   ],
   "source": [
    "dqn.fit(env, nb_steps=1500000, callbacks=[checkpoint_callback], log_interval=100000, visualize=False)\n",
    "\n",
    "# After training is done, we save the final weights one more time.\n",
    "dqn.save_weights(weights_filename, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b13dfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.sleep = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bf6953",
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.test(env, nb_episodes=1, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874bde42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
